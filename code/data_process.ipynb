{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6292a0-982a-4eff-b1e2-4d274b1ae653",
   "metadata": {},
   "source": [
    "# Data Cleaning and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f25c58-0f57-48fc-bf0b-e085dfdee4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "# !aws s3 ls s3://{bucket}/project/submissions/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b263c42-22df-4c28-bdc3-0ff9db7672c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyspark==3.4.0 in /opt/conda/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark==3.4.0) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup - Run only once per Kernel App\n",
    "%conda install https://anaconda.org/conda-forge/openjdk/11.0.1/download/linux-64/openjdk-11.0.1-hacce0ff_1021.tar.bz2\n",
    "\n",
    "# install PySpark\n",
    "%pip install pyspark==3.4.0\n",
    "\n",
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d387938b-de48-44a3-a091-fc600677b5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/conda/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/sagemaker-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/sagemaker-user/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6a3c965c-65b0-448d-8eb6-e18d716c2719;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.563 in central\n",
      ":: resolution report :: resolve 209ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.563 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6a3c965c-65b0-448d-8eb6-e18d716c2719\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/4ms)\n",
      "24/11/13 20:06:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/13 20:06:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PySparkApp\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\n",
    "    .config(\n",
    "        \"fs.s3a.aws.credentials.provider\",\n",
    "        \"com.amazonaws.auth.ContainerCredentialsProvider\",\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20107ebf-010f-4951-9da3-d1e1ad4a4eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/13 20:06:23 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_prefix_data_submissions = f\"project/submissions/yyyy=*\"\n",
    "s3_path = f\"s3a://{bucket}/{output_prefix_data_submissions}\"\n",
    "submissions = spark.read.parquet(s3_path, header=True)\n",
    "submissions = submissions.select(\"subreddit\", \"author\", \"title\", \"selftext\", \"num_comments\", \"score\", \"created_utc\", \"id\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80800c4-cea0-463a-8c9b-be1e5f38228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_prefix_data_comments = \"project/comments/yyyy=*\"\n",
    "s3_path = f\"s3a://{bucket}/{output_prefix_data_comments}\"\n",
    "comments = spark.read.parquet(s3_path, header=True)\n",
    "comments = comments.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"link_id\", \"id\", \"controversiality\",\"score\", \"created_utc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dce23b0-49c3-4dea-9026-c5bdc95444e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import functions as F\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb95b8ef-82f7-40c5-8839-85983e47952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_submissions = submissions \\\n",
    "    .withColumn(\"title\", F.lower(F.col(\"title\"))) \\\n",
    "    .filter(F.col(\"title\").rlike(r\"(?i)Trump|(?i)Biden\")) \\\n",
    "    .filter(~F.col(\"selftext\").contains(\"[deleted]\")) \\\n",
    "    .withColumn(\"date\", F.date_format(F.from_unixtime(F.col(\"created_utc\")), \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aff67448-b623-4cf2-9404-344eaafd4185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+--------------------+---------+------------+-----+-----------+-------+----------+\n",
      "|   subreddit|            author|               title| selftext|num_comments|score|created_utc|     id|      date|\n",
      "+------------+------------------+--------------------+---------+------------+-----+-----------+-------+----------+\n",
      "|   democrats|  BrianForCongress|every single majo...|         |           0|    1| 1721575517|1e8osif|2024-07-21|\n",
      "|    politics|         buddyboys|biden asking if h...|         |          76|    0| 1721575870|1e8oxdk|2024-07-21|\n",
      "|Conservative|         yuri_2022|biden announces h...|         |           5|   56| 1721576100|1e8p0bl|2024-07-21|\n",
      "|Conservative|         yuri_2022|going full trump:...|         |           0|    6| 1721576177|1e8p1cb|2024-07-21|\n",
      "|Conservative|         yuri_2022|new poll spells d...|         |           8|   31| 1721576350|1e8p3l4|2024-07-21|\n",
      "|Conservative|  Muted_Leader_327|proud to vote for...|[removed]|           0|    1| 1721576721|1e8p8l2|2024-07-21|\n",
      "|  Republican|Difficult-Lack9402|what’s one good t...|[removed]|           3|    1| 1721576743|1e8p8wn|2024-07-21|\n",
      "|   democrats| Capital-Water2505|trump now favored...|[removed]|           0|    1| 1721576755|1e8p926|2024-07-21|\n",
      "|   democrats|            D-R-AZ|biden is right to...|         |          10|  179| 1721576756|1e8p92l|2024-07-21|\n",
      "|Conservative|         yuri_2022|biden's fading ca...|         |           5|   25| 1721576898|1e8pazy|2024-07-21|\n",
      "|    politics|   WouldbeWanderer|secret service sa...|         |          21|    0| 1721576935|1e8pbi6|2024-07-21|\n",
      "|    politics|    BreathEcstatic|as we see trump c...|[removed]|           1|    1| 1721577207|1e8pf7v|2024-07-21|\n",
      "|Conservative|         [deleted]|our new timeline:...|[removed]|           0|    1| 1721577352|1e8ph6b|2024-07-21|\n",
      "|Conservative|intelligentreviews|trump outraised b...|         |           6|   84| 1721577409|1e8phy6|2024-07-21|\n",
      "|  Republican|interestingfactoid|trump outraised b...|         |           2|   20| 1721577458|1e8pil1|2024-07-21|\n",
      "|Conservative|intelligentreviews|trump: 'last week...|         |           0|   16| 1721577479|1e8piv0|2024-07-21|\n",
      "|  Republican|interestingfactoid|trump: 'last week...|         |          24|   75| 1721577507|1e8pj8a|2024-07-21|\n",
      "|Conservative|intelligentreviews|trump says he rec...|         |           4|   62| 1721577532|1e8pjjq|2024-07-21|\n",
      "|    politics|           Gygyfun|sen. joe manchin ...|         |           3|    3| 1721577542|1e8pjo8|2024-07-21|\n",
      "|  Republican|interestingfactoid|trump says he rec...|         |           4|   17| 1721577566|1e8pk0d|2024-07-21|\n",
      "+------------+------------------+--------------------+---------+------------+-----+-----------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_submissions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62b53602-f541-4151-9674-37e585d783df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_path = \"../data/csv/filtered_submissions.parquet\"\n",
    "\n",
    "# Write the DataFrame to a Parquet file\n",
    "filtered_submissions.write.parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff71689-5bf0-46ef-a989-cb9a1ae62e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "a = filtered_submissions.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b74c018-80bf-4fae-8314-25d991926338",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv(\"../data/csv/filtered_submissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fb0c5fc-fd32-4df7-a205-49e0d5c57b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:==>            (24 + 4) / 130][Stage 15:>                 (0 + 0) / 4]\r"
     ]
    }
   ],
   "source": [
    "trump_submissions = submissions \\\n",
    "    .withColumn(\"title\", F.lower(F.col(\"title\"))) \\\n",
    "    .filter(F.col(\"title\").rlike(r\"(?i)Trump\")) \\\n",
    "    .filter(~F.col(\"selftext\").contains(\"[deleted]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65b33dc1-736d-4edd-99c9-d84dc8e8034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_submissions = submissions \\\n",
    "    .withColumn(\"title\", F.lower(F.col(\"title\"))) \\\n",
    "    .filter(F.col(\"title\").rlike(r\"(?i)Biden\")) \\\n",
    "    .filter(~F.col(\"selftext\").contains(\"[deleted]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dee69ff0-4b98-456f-8152-85d9c2c3af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:====>          (36 + 4) / 130][Stage 15:>                 (0 + 0) / 4]\r"
     ]
    }
   ],
   "source": [
    "harris_submissions = submissions \\\n",
    "    .withColumn(\"title\", F.lower(F.col(\"title\"))) \\\n",
    "    .filter(F.col(\"title\").rlike(r\"(?i)Harris\")) \\\n",
    "    .filter(~F.col(\"selftext\").contains(\"[deleted]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd01245f-e4d4-4208-b99c-29ded4fe4719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trump_submissions.toPandas().to_csv(\"../data/csv/trump_submissions.csv\")\n",
    "biden_submissions.toPandas().to_csv(\"../data/csv/biden_submissions.csv\")\n",
    "harris_submissions.toPandas().to_csv(\"../data/csv/harris_submissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5271de1b-331a-4f9c-a602-fdc71e13a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_comments(filtered_submission):\n",
    "    # Collect the unique IDs from filtered_submissions into a set\n",
    "    post_ids = filtered_submission.select(\"id\").rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    # Prefix each post_id with \"t3_\" and update the post_ids set\n",
    "    prefixed_post_ids = {\"t3_\" + post_id for post_id in post_ids}\n",
    "    \n",
    "    # Filter the comments DataFrame\n",
    "    filtered_comments = comments.filter(F.col(\"link_id\").isin(prefixed_post_ids))\n",
    "    \n",
    "    return filtered_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "690f4a47-ba67-450b-8930-b1c4f323dc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# trump_comments = filter_comments(trump_submissions)\n",
    "# biden_comments = filter_comments(biden_submissions)\n",
    "# harris_comments = filter_comments(harris_submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "613f39b3-8f9e-4b0e-9cee-ff21dad194e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/08 22:45:40 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "ERROR:root:KeyboardInterrupt while sending command.               (3 + 5) / 130]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "[Stage 26:=>                                                      (4 + 4) / 130]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrump_comments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/csv/trump_comments.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m biden_comments\u001b[38;5;241m.\u001b[39mtoPandas()\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/csv/biden_comments.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m harris_comments\u001b[38;5;241m.\u001b[39mtoPandas()\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/csv/harris_comments.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:208\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    209\u001b[0m column_counter \u001b[38;5;241m=\u001b[39m Counter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    211\u001b[0m corrected_dtypes: List[Optional[Type]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/sql/dataframe.py:1216\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \n\u001b[1;32m   1198\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1216\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trump_comments.toPandas().to_csv(\"../data/csv/trump_comments.csv\")\n",
    "# biden_comments.toPandas().to_csv(\"../data/csv/biden_comments.csv\")\n",
    "# harris_comments.toPandas().to_csv(\"../data/csv/harris_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "797bc165-1e74-46b4-8e9f-318162d0233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_ids = trump_submissions.select(\"id\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "973351ba-8b0a-479f-b1d3-7fa1bddc353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trump_submissions.filter(F.col(\"num_comments\") != 0).select(\"id\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# trump_submissions.filter(F.col(\"num_comments\") != 0).selectExpr(\"id\").rdd.map(lambda row: row[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "088838a9-0d51-45bb-976e-f5edae702d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "harris_ids = submissions \\\n",
    "    .withColumn(\"title\", F.lower(F.col(\"title\"))) \\\n",
    "    .filter(F.col(\"title\").rlike(r\"(?i)Harris\")) \\\n",
    "    .filter(~F.col(\"selftext\").contains(\"[deleted]\")) \\\n",
    "    .filter(F.col(\"num_comments\") != 0) \\\n",
    "    .selectExpr(\"id\").rdd.map(lambda row: row[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20b062a9-a208-4034-9891-5cd3b977991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=====================================================>(129 + 1) / 130]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+--------------------+----------+-------+----------------+-----+-----------+-------+\n",
      "|   link_id|subreddit|              author|                body| parent_id|     id|controversiality|score|created_utc|     id|\n",
      "+----------+---------+--------------------+--------------------+----------+-------+----------------+-----+-----------+-------+\n",
      "|t3_1dswta6| politics|       AutoModerator|\\nAs a reminder, ...|t3_1dswta6|lb586l9|               0|    1| 1719850125|1dswta6|\n",
      "|t3_1dswta6| politics|       Brian24jersey|That’s right lol ...|t3_1dswta6|lb58gyy|               1|   -4| 1719850222|1dswta6|\n",
      "|t3_1dswta6| politics|           Tbone2797|I'm sure Republic...|t3_1dswta6|lb59hgr|               0|   27| 1719850555|1dswta6|\n",
      "|t3_1dswta6| politics|          bl3ckm3mba|Probably many sta...|t3_1dswta6|lb5a04i|               1|   -3| 1719850724|1dswta6|\n",
      "|t3_1dswta6| politics|           fairoaks2|As usual the Repu...|t3_1dswta6|lb5a1hl|               0|    8| 1719850736|1dswta6|\n",
      "|t3_1dswta6| politics|AggressiveBookBinder|Talk about unlike...|t3_1dswta6|lb5a45l|               0|   -1| 1719850761|1dswta6|\n",
      "|t3_1dswta6| politics| Ok-Conversation2707|Al Gore is the on...|t1_lb58gyy|lb5akzk|               0|    1| 1719850914|1dswta6|\n",
      "|t3_1dswta6| politics| Ok-Conversation2707|Al Gore is the on...|t1_lb59hgr|lb5arqm|               1|   -3| 1719850977|1dswta6|\n",
      "|t3_1dswta6| politics| a_fine_day_to_ligma|[the biden campai...|t3_1dswta6|lb5awb5|               0|    3| 1719851019|1dswta6|\n",
      "|t3_1dswta6| politics|       Incorrect1012|I just need Democ...|t3_1dswta6|lb5aznm|               0|    7| 1719851049|1dswta6|\n",
      "|t3_1dswta6| politics|         deekaydubya|No that would be ...|t1_lb5arqm|lb5bxsw|               0|    0| 1719851357|1dswta6|\n",
      "|t3_1dswta6| politics|            srs_time|Even if he doesn'...|t1_lb59hgr|lb5c2b8|               0|    4| 1719851398|1dswta6|\n",
      "|t3_1dswta6| politics|             Utvales|I don't see how. ...|t3_1dswta6|lb5c73n|               0|    2| 1719851441|1dswta6|\n",
      "|t3_1dswta6| politics|          877GoalNow|>I wouldn't be su...|t1_lb5a04i|lb5cf7u|               0|    0| 1719851516|1dswta6|\n",
      "|t3_1dswta6| politics|           anacondra|Breaking news: Ku...|t3_1dswta6|lb5dscg|               0|    1| 1719851959|1dswta6|\n",
      "|t3_1dswta6| politics|   Fartsinthemachine|Me when I don’t k...|t1_lb5a1hl|lb5dx0k|               0|    7| 1719852001|1dswta6|\n",
      "|t3_1dswta6| politics|               OiUey|Nope. We only ele...|t3_1dswta6|lb5e511|               0|    2| 1719852073|1dswta6|\n",
      "|t3_1dswta6| politics|               OiUey|They made their \"...|t1_lb5aznm|lb5ecdn|               0|    0| 1719852139|1dswta6|\n",
      "|t3_1dswta6| politics|           snoo_spoo|I literally have ...|t1_lb5arqm|lb5ekcs|               0|    6| 1719852211|1dswta6|\n",
      "|t3_1dswta6| politics|       Incorrect1012|There’s also the ...|t1_lb5ecdn|lb5eyff|               0|    6| 1719852336|1dswta6|\n",
      "+----------+---------+--------------------+--------------------+----------+-------+----------------+-----+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "submission_ids_df = spark.createDataFrame([(id,) for id in harris_ids], [\"id\"])\n",
    "\n",
    "# Step 2: Modify the IDs to match the `link_id` format\n",
    "submission_ids_df = submission_ids_df.withColumn(\"link_id\", F.concat(F.lit(\"t3_\"), submission_ids_df[\"id\"]))\n",
    "\n",
    "# Step 3: Join and filter the `comments` DataFrame based on the `link_id`\n",
    "filtered_comments = comments.join(submission_ids_df, on=\"link_id\", how=\"inner\")\n",
    "\n",
    "# Now `filtered_comments` contains only comments with `link_id`s matching the selected IDs.\n",
    "filtered_comments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef2fbe37-b033-44da-8cec-aef3925dcbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_comments.toPandas().to_csv(\"../data/csv/harris_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a6e46-f009-4112-8bb2-bf3fb2087e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
